{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0f4VZ70sVb23"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import corner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZr4MeMPVb25"
   },
   "source": [
    "# 11a: MCMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6U5XK6I_Vb26"
   },
   "source": [
    "## Parameter uncertainty with MCMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QScyHvgmVb26"
   },
   "source": [
    "So we can now do MC simulations. We understand this really just means simulate many times. So what is MCMC and how is it different?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_6MRfrHVb26"
   },
   "source": [
    "**MCMC is a form of MC but not all MCs are MCMCs!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_pL0sTWyVb26"
   },
   "source": [
    "What is so special about MCMC?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zrMSby0LVb27"
   },
   "source": [
    "MCMC displays the $\\textit{Markov property}$: the next state just depends on the current one (think snakes and ladders!).\n",
    "\n",
    "MCMC's are a Markov process.\n",
    "\n",
    "$P(x_{n+1})$ depends only on $P(x_{n})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FtiQbFjAVb27"
   },
   "source": [
    "Markov chains are useful because of their 'stationary distribution'. Let's work through an example to work out what that means.\n",
    "\n",
    "You have three goldfish bowls; A, B and C.\n",
    " - The pipes between them have different opening sizes so where we move next has different probabilities.\n",
    "    - The fish might even stay in the same bowl\n",
    " - The goldfish doesn't remember where they were before, so they may choose to stay or move at any point\n",
    " - However, there is a cat sleeping by bowl B, so if the goldfish is in there, they will leave straight away\n",
    "\n",
    "The probabilities of moving are as follows:\n",
    " - In Bowl A, the next bowl probabilities are A:0.5, B:0.2, C:0.3\n",
    " - In Bowl B, the next bowl probabilities are A:0.6, B:0 (the cat!), C:0.4\n",
    " - In Bowl C, the next bowl probabilities are A:0.3, B:0.4, C:0.3\n",
    "\n",
    "This is an example of a 3 state system: we can be in state (bowl) A, B or C. The lines and numbers indicate the probability we will stay in this state next or move on to one of the other states. These probabilities are written out in the transition matrix below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WDB41bVmVb27"
   },
   "source": [
    "$$\\begin{bmatrix}\n",
    "0.5 & 0.2 & 0.3 \\\\\n",
    "0.6 & 0 & 0.4 \\\\\n",
    "0.3 & 0.4 & 0.3\n",
    "\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PsGnWnCsVb27"
   },
   "source": [
    "Our bowls can be considered as vectors;\n",
    "$$A=[1,0,0]$$\n",
    "$$B=[0,1,0]$$\n",
    "$$C=[0,0,1]$$\n",
    "\n",
    "Let's say we start in bowl A, so we start from $[1,0,0]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pBvAV8SVVb28"
   },
   "source": [
    "The probability for the next state $x$ will be:\n",
    "\n",
    "$$P(x_{1})=\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 0\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "0.5 & 0.2 & 0.3 \\\\\n",
    "0.6 & 0 & 0.4 \\\\\n",
    "0.3 & 0.4 & 0.3\n",
    "\\end{bmatrix}\n",
    "=\\begin{bmatrix}\n",
    "0.5 & 0.2 & 0.3\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "then the probability that the goldfish is in each bowl after one step is 0.5, 0.2 and 0.3 respectively, as expected.\n",
    "\n",
    "So we move on; what is the probability that the fish will be in each bowl after two moves?\n",
    "\n",
    "$$P(x_{2})=\n",
    "\\begin{bmatrix}\n",
    "0.5 & 0.2 & 0.3\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "0.5 & 0.2 & 0.3 \\\\\n",
    "0.6 & 0 & 0.4 \\\\\n",
    "0.3 & 0.4 & 0.3\n",
    "\\end{bmatrix}\n",
    "= ... (\\textrm{if you want to}) ...$$\n",
    "We can carry this on until we reach an equilibrium.\n",
    "\n",
    "To explain what this means, let's change notation so the 'transition matrix' is called $\\mathbf{Q}$ and the vector multiplying it is $\\vec{a}_{n}$\n",
    "\n",
    "so\n",
    "\n",
    "$$\\vec{a}_{n}\\mathbf{Q}=\\vec{a}_{n+1}$$\n",
    "$$\\vec{a}_{n+1}\\mathbf{Q}=\\vec{a}_{n+2}$$\n",
    "\n",
    "and so on.\n",
    "\n",
    "An important property for finite state Markov chains is they will reach an $\\textit{equlibrium}$ where:\n",
    "\n",
    "$$\\vec{a}_X\\mathbf{Q}=\\vec{a}_X$$\n",
    "\n",
    "(this is the *eigenvector* with an *eigenvalue* of one)\n",
    "\n",
    "Let's see this with a simulation for our goldfish being in bowls A, B, C above.\n",
    "\n",
    "If we are going to reach an equilibrium, then no matter what starting value we give, we should converge to the same average probability of being in state A, B or C. Try this below by changing the initial state and the number of steps.\n",
    "\n",
    "Add comments to the below code cell explaining what each part does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R35yOrdBVb28",
    "outputId": "0930ed2b-9d2e-4315-d82b-75f5f5e7a181"
   },
   "outputs": [],
   "source": [
    "### Try me for different starting points A, B or C and\n",
    "### different numbers of steps\n",
    "initial_state=np.matrix([[1,0,0]])\n",
    "number_of_steps=3\n",
    "\n",
    "transition_matrix=np.matrix([[0.5,0.2,0.3],[0.6,0,0.4],[0.3,0.4,0.3]])\n",
    "\n",
    "def next_step(current,transition):\n",
    "    next_step = np.dot(current,transition)\n",
    "    return next_step\n",
    "\n",
    "objects = ('A', 'B', 'C')\n",
    "y_pos = np.arange(len(objects))\n",
    "input_0=initial_state\n",
    "for i in range(number_of_steps):\n",
    "    input_1=next_step(input_0,transition_matrix)\n",
    "    plt.bar(y_pos, np.squeeze(np.asarray(input_1)), align='center', color='red', alpha=0.1)\n",
    "    input_0=input_1\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.title('Probability of being in state A, B or C')\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Probability')\n",
    "\n",
    "print(\"Final state: \", input_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4DjduyJoVb29"
   },
   "source": [
    "What do you notice about the above plot. Hint: what do the final values add up to?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUoEEcv1Vb29"
   },
   "source": [
    "## Going back to our data from 10a and our straight line model, let's use MCMC to fit the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9CpsEmf8Vb29"
   },
   "source": [
    "A reminder of what our data looks like: (Copied from notebook 10a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vl6x7xZvVb29",
    "outputId": "8fcab064-11be-46f0-b66c-52893a389e01"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'y')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setting a seed - what does this do?\n",
    "np.random.seed(123)\n",
    "\n",
    "# The \"true\" parameters.\n",
    "m_true = -0.9\n",
    "b_true = 4.0\n",
    "f_true = 0.9 \n",
    "\n",
    "# Generate some synthetic data from the model.\n",
    "N = 35 # number of data points to generate\n",
    "x = np.sort(10 * np.random.rand(N)) # randomly generate x\n",
    "yerr = 0.1 + 0.5 * np.random.rand(N) # randomy generate yerr\n",
    "y = m_true * x + b_true # y = m*x + b\n",
    "y += np.abs(f_true * y) * np.random.randn(N)\n",
    "y += yerr * np.random.randn(N)\n",
    "\n",
    "# plotting this data\n",
    "plt.errorbar(x, y, yerr=yerr, fmt=\".k\", capsize=3,label='Our data')\n",
    "\n",
    "# plotting the model we drew the mock data from\n",
    "x0 = np.linspace(0, 10, 500)\n",
    "plt.plot(x0, m_true * x0 + b_true, \"r--\", alpha=1.0, lw=1, label='True model')\n",
    "\n",
    "# Always remember to apropriately label your plots!\n",
    "plt.legend()\n",
    "plt.xlim(0, 10)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"x\",fontsize=20)\n",
    "plt.ylabel(\"y\",fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hKpg71YkVb29"
   },
   "source": [
    "You may have come across Bayes theorem below (think school, venn diagrams and rearranging formulae for conditional probability - if you haven't / don't remember it, wikipedia it!):\n",
    "\n",
    "$$P(A|B) = \\frac{P(A)P(B|A)}{P(B)}$$\n",
    "\n",
    "Changing A and B into things we care about:\n",
    "\n",
    "$$P(model | data) = \\frac{P(model)P(data | model)}{P(data)}$$\n",
    "\n",
    "The names assigned to the parts of the equations are this:\n",
    "\n",
    "$$Posterior = \\frac{Prior~\\times~Likelihood}{Evidence}$$\n",
    "\n",
    "\n",
    "\n",
    "We usually want to know what is the probability that our model is correct given the data - this is what is on the left hand side. It's name is the 'posterior' distribution.\n",
    "\n",
    "But this can be hard to find...why?\n",
    "\n",
    "Well... $P(model)$ (called the prior) is easy: this is just the prior information we are choosing to include.\n",
    "\n",
    "$P(data | model)$ (called the likelihood) is usually not too hard to get the shape of the distribution. However, if we are doing this naively and evaluating the data given the model on a full grid of all possible parameters it might take forever! For example, if we have a 5 parameter model and we were to evaluate the likelihood at each of 10 values we will already have $10^{5}$ grid points!\n",
    "\n",
    "But $P(data)$ (the evidence) is usually pretty difficult! To calculate $P(data)$ you need to have the $P(data | \\textit{every hypothesis})$, this could take infinite values depending on your situation. But $P(data)$ doesn't depend on the model parameters itself. So if we can work out the shape of the final distribution we could then sample from it and use our samples to work out the probabilities.\n",
    "\n",
    "MCMC provides us a way to sample from the distribution by creating a chain where the 'stationary' or equilibrium distribution is the same shape as the posterior distribution, but we don't need to know the exact height of this distribution.\n",
    "\n",
    "The goal is to construct a sequence which walks around in such a way that the chain itself will have the desired stationary distribution.\n",
    "\n",
    "One algorithm is the $\\textit{metropolis hastings}$ algorithm. Let's code it up ourselves and refit our line from the start.\n",
    "\n",
    "But first let's write some functions which will allow us to calculate the likelihood and prior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gnLbNEJpVb2-"
   },
   "source": [
    "## The likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "suPCoR5HVb2-"
   },
   "source": [
    "Our model is below. Let's assume this is a good model and use MCMC to find the uncertainty on the parameters.\n",
    " $$y = mx+b$$\n",
    "\n",
    "with variance $s_n^2$\n",
    "\n",
    " $$\n",
    "    s_n^2 = \\sigma_n^2+f^2\\,(m\\,x_n+b)^2 \\quad .\n",
    "$$\n",
    "\n",
    "This likelihood function is simply a Gaussian where the variance is\n",
    "underestimated by some fractional amount,  $f$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5B9A3pJ8Vb2-"
   },
   "source": [
    "The linear least squares method used before in the basic MC example assumed the error bars are correct, Gaussian and independent.\n",
    "\n",
    "We know this is not the case as we set up the model. (Remember we said there was additional intrinsic scatter denoted by $f$).\n",
    "\n",
    "Unfortunately, there isn't a generalisation of least squares that supports a model like the one that we know to be true.\n",
    "\n",
    "We can instead write down the log (_natural log_) likelihood function and numerically maximise it. (We use the log simply because products in log are sums and that makes life easier)\n",
    "\n",
    "In mathematical notation, the correct log likelihood function is:\n",
    "\n",
    "$$\n",
    "    \\ln\\,p(y\\,|\\,x,\\sigma,m,b,f) =\n",
    "    -\\frac{1}{2} \\sum_n \\left[\n",
    "        \\frac{(y_n-m\\,x_n-b)^2}{s_n^2}\n",
    "        + \\ln \\left ( 2\\pi\\,s_n^2 \\right )\n",
    "    \\right]\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "    s_n^2 = \\sigma_n^2+f^2\\,(m\\,x_n+b)^2 \\quad .\n",
    "$$\n",
    "\n",
    "This likelihood function is simply a Gaussian where the variance is\n",
    "underestimated by some fractional amount:  $f$.\n",
    "\n",
    "I have written the equation in python below but there are 4 bugs - find them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k9_VW7WQVb2-"
   },
   "outputs": [],
   "source": [
    "def log_likelihood(theta, x, y, yerr):\n",
    "    m, b, log_f = theta # theta contains our parameters to infer\n",
    "    model = m ** x + b # our simple straight line\n",
    "    sigma2 = y_err ** 2 + model ** 2 * np.exp(2 * log_f)\n",
    "    ln_like = -0.5 * np.prod((y - model) ** 2 / sigma2 + np.log10(sigma2))\n",
    "    return ln_like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xSOWDfr4Vb2-"
   },
   "source": [
    "If we drew samples from the likelihood rather than the posterior what would we be doing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yk9n_KBFVb2-"
   },
   "source": [
    "## The prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51AdKsZsVb2-"
   },
   "source": [
    " - What does this function below do?\n",
    "    - Discuss it with each other.\n",
    " - What are the priors we are setting on our parameters?\n",
    "    - Are they reasonable?\n",
    " - Add comments to the function so that you can remember this later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EAZd9xBzVb2_"
   },
   "outputs": [],
   "source": [
    "def log_prior(theta):\n",
    "    m, b, log_f = theta\n",
    "    if -5.0 < m < 0.5 and 0.0 < b < 10.0 and -10.0 < log_f < 1.0:\n",
    "        return 0.0\n",
    "    return -np.inf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AvvPQm_OVb2_"
   },
   "source": [
    "## The evidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-LtWSoHaVb2_"
   },
   "source": [
    "We shall ignore the evidence - it is not necessary here - if you don't remember why, go back and read the part about Bayes theorem!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wHlhhnK5Vb2_"
   },
   "source": [
    "## The posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WifaFUeFVb2_"
   },
   "outputs": [],
   "source": [
    "def log_probability(theta, x, y, yerr):\n",
    "    lp = log_prior(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + log_likelihood(theta, x, y, yerr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXP6PkWIVb2_"
   },
   "source": [
    "Why have we used logs above? (hint, try doing `np.exp(1000)` and `np.exp(-1000)`) What does this function do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y9SqdbXNVb3A"
   },
   "source": [
    "Now we are ready to write our MH algorithm and fit stuff with our MCMC!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k9LYZdWCVb3A"
   },
   "source": [
    "## Recipe for MCMC using metropolis hastings algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jR_OGfKLVb3A"
   },
   "source": [
    "From the lecture:\n",
    "1. Choose some random values for the parameters\n",
    "2. Determine the posterior at these values\n",
    "3. Propose a new step at some new values\n",
    "4. Determine the posterior at these new values\n",
    "5. Compare the two (divide them)\n",
    "6. Generate a random number and compare this to the ratio of the posteriors to decide if you move or stay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41PTpx4NVb3A"
   },
   "source": [
    "#### Write a few functions which will perform the MH algorithm\n",
    "\n",
    "(you should understand and comment the code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cgRdy3q-Vb3A"
   },
   "outputs": [],
   "source": [
    "# Defines the next sample in the chain\n",
    "def transition_model(theta):\n",
    "    return theta_new\n",
    "\n",
    "# Defines whether to accept or reject the new sample\n",
    "def acceptance(logl, logl_new):\n",
    "    return accept\n",
    "\n",
    "\n",
    "def metropolis_hastings(log_probability, transition_model, param_init,iterations,x,y,yerr,acceptance_rule):\n",
    "    # log_probability: posterior calculation\n",
    "    # transition_model(x): gaussian proposal\n",
    "    # param_init: a starting sample\n",
    "    # iterations: number of accepted to generated\n",
    "    # x,y,yerr: the data that we wish to model\n",
    "    # acceptance_rule(theta_prob,theta_prob_new): decides whether to accept or reject the new sample\n",
    "    theta = param_init\n",
    "    accepted = []\n",
    "    # Can you fill me in?\n",
    "    return np.array(accepted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2fYf6BjVb3E"
   },
   "source": [
    "## Fitting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "po__cEzzVb3F"
   },
   "source": [
    "Using some initial starting parameters which are not the correct answer so that we can see it works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "93tq3Yb-Vb3F",
    "outputId": "17ed6183-37dc-4ba2-845f-e8d3832f39d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.9 4.0 0.9 -0.045757490560675115\n",
      "-0.15000000000000002 1.1428571428571428 0.0818181818181819 -1.0871501757188997\n"
     ]
    }
   ],
   "source": [
    "m_init=m_true - m_true/1.2\n",
    "b_init=b_true - b_true/1.4\n",
    "f_init=f_true - f_true/1.1\n",
    "print(m_true,b_true,f_true, np.log10(f_true))\n",
    "print(m_init,b_init,f_init, np.log10(f_init))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8T7YZu_4Vb3F"
   },
   "outputs": [],
   "source": [
    "theta_init = [m_init,b_init,f_init]\n",
    "\n",
    "accepted = metropolis_hastings(\n",
    "    log_probability,\n",
    "    transition_model,\n",
    "    theta_init,\n",
    "    200000,\n",
    "    x, y, yerr,\n",
    "    acceptance\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zhwusRZzVb3F"
   },
   "source": [
    "Below is some code which will visualise the results as the chain moves along for parameter b:\n",
    " - Plot it also for parameters a and f\n",
    " - What do you notice about the beginning of the chain?\n",
    " - Would you include all the samples when quoting your results for the best fit and the 1 $\\sigma$ limits on the parameters?\n",
    "    - Try varying the number of samples plotted in each panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rjrR06i4Vb3F",
    "outputId": "a8fd2a43-86dd-418f-f2dd-db9398a2df02"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(2,1,1)\n",
    "\n",
    "parameter = 'b'\n",
    "dimension = 1\n",
    "\n",
    "n_samples = 10\n",
    "ax.plot(accepted[0:n_samples,dimension], 'b.', label='Accepted',alpha=0.5)\n",
    "ax.set_xlabel(\"Iteration\", fontsize=20)\n",
    "ax.set_ylabel(f\"parameter {parameter}\", fontsize=20)\n",
    "ax.set_title(f\"MCMC sampling for ${parameter}$ with Metropolis-Hastings. First {n_samples} samples are shown.\", fontsize=15)\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "\n",
    "show_final_samples = 150\n",
    "initial_sample = accepted.shape[0] - show_final_samples\n",
    "\n",
    "ax2 = fig.add_subplot(2,1,2)\n",
    "ax2.plot(np.arange(show_final_samples) + initial_sample, accepted[initial_sample:,dimension], 'b.', label='Accepted',alpha=0.5)\n",
    "ax2.set_xlabel(\"Iteration\", fontsize=20)\n",
    "ax2.set_ylabel(\"parameter b\", fontsize=20)\n",
    "ax2.set_title(f\"MCMC sampling for $b$ with Metropolis-Hastings, the last {show_final_samples} samples are shown.\", fontsize=15)\n",
    "ax2.grid()\n",
    "ax2.legend()\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uLOReckxVb3F"
   },
   "source": [
    "Let's use a corner plot to explore our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pg9c6zLyVb3G",
    "outputId": "af200a8f-ad55-4341-e5f2-b5295518d4ac"
   },
   "outputs": [],
   "source": [
    "# This is the number of samples to discard at the start of the MCMC\n",
    "samples_start = 0\n",
    "\n",
    "mh_samples = np.array([accepted[samples_start:,0],accepted[samples_start:,1],accepted[samples_start:,2]]).T\n",
    "labels = [\"m\", \"b\", \"log(f)\"]\n",
    "fig = corner.corner(mh_samples, labels=labels, truths=[m_true,b_true,np.log(f_true)], quantiles=[0.16, 0.5, 0.84], levels=(1-np.exp(-0.5),), show_titles=True, title_kwargs={\"fontsize\": 15}, smooth=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iPcDJXerVb3G"
   },
   "source": [
    "Another way to visualise this would be to plot samples from your distribution of parameters over the top of your data. For example see the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZaCA66l5Vb3G",
    "outputId": "fe7f7252-f362-48de-d5a1-15c4b82836d3"
   },
   "outputs": [],
   "source": [
    "# So it's not too much on the plot, we will only plot 100 lines:\n",
    "inds = np.random.randint(len(mh_samples), size=100)\n",
    "for ind in inds:\n",
    "    sample = mh_samples[ind]\n",
    "    plt.plot(x0, np.dot(np.vander(x0, 2), sample[:2]), \"C1\", alpha=0.1) # look up the vander function and see what it is doing here\n",
    "plt.errorbar(x, y, yerr=yerr, fmt=\".k\", capsize=0, label='data')\n",
    "plt.plot(x0, m_true * x0 + b_true, \"k\", label=\"truth\")\n",
    "plt.plot([],[], 'C1', label='samples')\n",
    "plt.legend(fontsize=14)\n",
    "plt.xlim(0, 10)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"x\", fontsize=20)\n",
    "plt.ylabel(\"y\", fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dz4I58UwVb3G"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
